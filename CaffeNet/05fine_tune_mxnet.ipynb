{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "#         path_imgrec         = '/data4/srip_face/img/jump_detector/old/jump_train_old.rec', \n",
    "        path_imgrec         = '/data4/srip_face/img/jump_detector/jump_train.rec', \n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "#         path_imgrec         = '/data4/srip_face/img/jump_detector/old/jump_valid_old.rec',\n",
    "        path_imgrec         = '/data4/srip_face/img/jump_detector/jump_valid.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "        \n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/caffenet/caffenet', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('caffenet', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='drop7'):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = symbol.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc8')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc8' not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus=1, num_epoch=1):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)] # replace mx.gpu by mx.cpu for CPU training\n",
    "    mod = mx.mod.Module(symbol=symbol, context=devs)\n",
    "    mod.bind(data_shapes=train.provide_data, label_shapes=train.provide_label)\n",
    "    mod.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=1))\n",
    "    mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "    \n",
    "    mod.fit(train, val, \n",
    "        num_epoch=num_epoch,\n",
    "        batch_end_callback = mx.callback.log_train_metric(100,True),\n",
    "        epoch_end_callback = mx.callback.do_checkpoint(\"caffenet-mxnet-jump-start-bootstrap\", 1),\n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.0009},\n",
    "        eval_metric='acc')\n",
    "#        eval_metric=mx.metric.CrossEntropy())\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-14 10:58:42,616 Already bound, ignoring bind()\n",
      "/home/srip_face/.local/lib/python2.7/site-packages/mxnet/module/base_module.py:464: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "2017-09-14 10:58:47,265 Iter[0] Batch[0] Train-accuracy=0.273438\n",
      "2017-09-14 10:59:09,130 Iter[0] Batch[100] Train-accuracy=0.799687\n",
      "2017-09-14 10:59:30,972 Iter[0] Batch[200] Train-accuracy=0.827031\n",
      "2017-09-14 10:59:36,644 Epoch[0] Train-accuracy=0.823618\n",
      "2017-09-14 10:59:36,646 Epoch[0] Time cost=54.001\n",
      "2017-09-14 10:59:40,686 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0001.params\"\n",
      "2017-09-14 10:59:44,244 Epoch[0] Validation-accuracy=0.788352\n",
      "2017-09-14 10:59:44,354 Iter[1] Batch[0] Train-accuracy=0.804688\n",
      "2017-09-14 11:00:06,213 Iter[1] Batch[100] Train-accuracy=0.837344\n",
      "2017-09-14 11:00:28,067 Iter[1] Batch[200] Train-accuracy=0.843047\n",
      "2017-09-14 11:00:33,740 Epoch[1] Train-accuracy=0.844952\n",
      "2017-09-14 11:00:33,743 Epoch[1] Time cost=49.496\n",
      "2017-09-14 11:00:37,572 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0002.params\"\n",
      "2017-09-14 11:00:40,479 Epoch[1] Validation-accuracy=0.796165\n",
      "2017-09-14 11:00:40,583 Iter[2] Batch[0] Train-accuracy=0.835938\n",
      "2017-09-14 11:01:02,452 Iter[2] Batch[100] Train-accuracy=0.843281\n",
      "2017-09-14 11:01:24,313 Iter[2] Batch[200] Train-accuracy=0.855469\n",
      "2017-09-14 11:01:29,770 Epoch[2] Train-accuracy=0.850625\n",
      "2017-09-14 11:01:29,771 Epoch[2] Time cost=49.288\n",
      "2017-09-14 11:01:35,506 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0003.params\"\n",
      "2017-09-14 11:01:38,316 Epoch[2] Validation-accuracy=0.804443\n",
      "2017-09-14 11:01:38,418 Iter[3] Batch[0] Train-accuracy=0.851562\n",
      "2017-09-14 11:02:00,528 Iter[3] Batch[100] Train-accuracy=0.854609\n",
      "2017-09-14 11:02:22,462 Iter[3] Batch[200] Train-accuracy=0.860625\n",
      "2017-09-14 11:02:28,177 Epoch[3] Train-accuracy=0.848558\n",
      "2017-09-14 11:02:28,183 Epoch[3] Time cost=49.866\n",
      "2017-09-14 11:02:33,587 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0004.params\"\n",
      "2017-09-14 11:02:36,967 Epoch[3] Validation-accuracy=0.816051\n",
      "2017-09-14 11:02:37,076 Iter[4] Batch[0] Train-accuracy=0.867188\n",
      "2017-09-14 11:02:59,112 Iter[4] Batch[100] Train-accuracy=0.859141\n",
      "2017-09-14 11:03:21,227 Iter[4] Batch[200] Train-accuracy=0.863125\n",
      "2017-09-14 11:03:26,919 Epoch[4] Train-accuracy=0.851863\n",
      "2017-09-14 11:03:26,923 Epoch[4] Time cost=49.953\n",
      "2017-09-14 11:03:32,058 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0005.params\"\n",
      "2017-09-14 11:03:35,546 Epoch[4] Validation-accuracy=0.827637\n",
      "2017-09-14 11:03:35,650 Iter[5] Batch[0] Train-accuracy=0.875000\n",
      "2017-09-14 11:03:57,599 Iter[5] Batch[100] Train-accuracy=0.864922\n",
      "2017-09-14 11:04:19,717 Iter[5] Batch[200] Train-accuracy=0.869531\n",
      "2017-09-14 11:04:25,220 Epoch[5] Train-accuracy=0.872188\n",
      "2017-09-14 11:04:25,224 Epoch[5] Time cost=49.675\n",
      "2017-09-14 11:04:31,101 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0006.params\"\n",
      "2017-09-14 11:04:34,131 Epoch[5] Validation-accuracy=0.828835\n",
      "2017-09-14 11:04:34,238 Iter[6] Batch[0] Train-accuracy=0.867188\n",
      "2017-09-14 11:04:56,278 Iter[6] Batch[100] Train-accuracy=0.866953\n",
      "2017-09-14 11:05:18,215 Iter[6] Batch[200] Train-accuracy=0.875469\n",
      "2017-09-14 11:05:23,915 Epoch[6] Train-accuracy=0.867188\n",
      "2017-09-14 11:05:23,918 Epoch[6] Time cost=49.781\n",
      "2017-09-14 11:05:29,164 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0007.params\"\n",
      "2017-09-14 11:05:34,172 Epoch[6] Validation-accuracy=0.827148\n",
      "2017-09-14 11:05:34,291 Iter[7] Batch[0] Train-accuracy=0.867188\n",
      "2017-09-14 11:05:56,504 Iter[7] Batch[100] Train-accuracy=0.869609\n",
      "2017-09-14 11:06:18,444 Iter[7] Batch[200] Train-accuracy=0.879766\n",
      "2017-09-14 11:06:24,142 Epoch[7] Train-accuracy=0.868690\n",
      "2017-09-14 11:06:24,145 Epoch[7] Time cost=49.966\n",
      "2017-09-14 11:06:30,890 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0008.params\"\n",
      "2017-09-14 11:06:34,250 Epoch[7] Validation-accuracy=0.836411\n",
      "2017-09-14 11:06:34,384 Iter[8] Batch[0] Train-accuracy=0.828125\n",
      "2017-09-14 11:06:56,301 Iter[8] Batch[100] Train-accuracy=0.877344\n",
      "2017-09-14 11:07:28,738 Iter[8] Batch[200] Train-accuracy=0.881328\n",
      "2017-09-14 11:07:37,289 Epoch[8] Train-accuracy=0.873437\n",
      "2017-09-14 11:07:37,292 Epoch[8] Time cost=63.016\n",
      "2017-09-14 11:07:43,021 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0009.params\"\n",
      "2017-09-14 11:07:46,314 Epoch[8] Validation-accuracy=0.838305\n",
      "2017-09-14 11:07:46,421 Iter[9] Batch[0] Train-accuracy=0.859375\n",
      "2017-09-14 11:08:08,591 Iter[9] Batch[100] Train-accuracy=0.876719\n",
      "2017-09-14 11:08:30,674 Iter[9] Batch[200] Train-accuracy=0.880078\n",
      "2017-09-14 11:08:36,369 Epoch[9] Train-accuracy=0.878005\n",
      "2017-09-14 11:08:36,372 Epoch[9] Time cost=50.053\n",
      "2017-09-14 11:08:41,620 Saved checkpoint to \"caffenet-mxnet-jump-start-bootstrap-0010.params\"\n",
      "2017-09-14 11:08:45,040 Epoch[9] Validation-accuracy=0.847168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('accuracy', 0.845407196969697)]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2 # This is binary classification\n",
    "batch_per_gpu = 128\n",
    "num_gpus = 1\n",
    "epoch = 10\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train, val) = get_iterators(batch_size)\n",
    "mod = fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus, epoch)\n",
    "metric = mx.metric.Accuracy()\n",
    "mod_score = mod.score(val, metric)\n",
    "print mod_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'caffenet-mxnet-jump-start-128-bootstrap'\n",
    "mc = mod.save_checkpoint(prefix, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
