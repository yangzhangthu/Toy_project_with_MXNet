{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = '/data4/srip_face/img/jump_detector/old/jump_train_old.rec', \n",
    "#         path_imgrec         = '/data4/srip_face/img/jump_detector/jump_train.rec', \n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = '/data4/srip_face/img/jump_detector/old/jump_valid_old.rec',\n",
    "#         path_imgrec         = '/data4/srip_face/img/jump_detector/jump_valid.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "        \n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/caffenet/caffenet', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('caffenet', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='drop7'):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = symbol.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc8')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc8' not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus=1, num_epoch=1):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)] # replace mx.gpu by mx.cpu for CPU training\n",
    "    mod = mx.mod.Module(symbol=symbol, context=devs)\n",
    "    mod.bind(data_shapes=train.provide_data, label_shapes=train.provide_label)\n",
    "    mod.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=1))\n",
    "    mod.set_params(arg_params, aux_params, allow_missing=True)\n",
    "    \n",
    "    mod.fit(train, val, \n",
    "        num_epoch=num_epoch,\n",
    "        batch_end_callback = mx.callback.log_train_metric(100,True),\n",
    "#         epoch_end_callback = mx.callback.do_checkpoint(\"caffenet-mxnet-jump-start-bootstrap\", 1),\n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.0009},\n",
    "        eval_metric='acc')\n",
    "#        eval_metric=mx.metric.CrossEntropy())\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-17 22:23:50,061 Already bound, ignoring bind()\n",
      "/home/srip_face/.local/lib/python2.7/site-packages/mxnet/module/base_module.py:464: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "2017-09-17 22:25:44,480 Iter[0] Batch[0] Train-accuracy=0.296875\n",
      "2017-09-17 22:26:06,441 Iter[0] Batch[100] Train-accuracy=0.804609\n",
      "2017-09-17 22:26:12,549 Epoch[0] Train-accuracy=0.849888\n",
      "2017-09-17 22:26:12,553 Epoch[0] Time cost=141.877\n",
      "2017-09-17 22:26:18,482 Epoch[0] Validation-accuracy=0.889205\n",
      "2017-09-17 22:26:18,586 Iter[1] Batch[0] Train-accuracy=0.875000\n",
      "2017-09-17 22:26:40,436 Iter[1] Batch[100] Train-accuracy=0.863516\n",
      "2017-09-17 22:26:46,547 Epoch[1] Train-accuracy=0.874721\n",
      "2017-09-17 22:26:46,549 Epoch[1] Time cost=28.065\n",
      "2017-09-17 22:26:51,949 Epoch[1] Validation-accuracy=0.909564\n",
      "2017-09-17 22:26:52,061 Iter[2] Batch[0] Train-accuracy=0.914062\n",
      "2017-09-17 22:27:13,919 Iter[2] Batch[100] Train-accuracy=0.879844\n",
      "2017-09-17 22:27:20,025 Epoch[2] Train-accuracy=0.883650\n",
      "2017-09-17 22:27:20,027 Epoch[2] Time cost=28.074\n",
      "2017-09-17 22:27:25,355 Epoch[2] Validation-accuracy=0.903809\n",
      "2017-09-17 22:27:25,460 Iter[3] Batch[0] Train-accuracy=0.843750\n",
      "2017-09-17 22:27:47,311 Iter[3] Batch[100] Train-accuracy=0.884844\n",
      "2017-09-17 22:27:53,424 Epoch[3] Train-accuracy=0.892299\n",
      "2017-09-17 22:27:53,425 Epoch[3] Time cost=28.068\n",
      "2017-09-17 22:27:58,945 Epoch[3] Validation-accuracy=0.910511\n",
      "2017-09-17 22:27:59,051 Iter[4] Batch[0] Train-accuracy=0.914062\n",
      "2017-09-17 22:28:20,909 Iter[4] Batch[100] Train-accuracy=0.894297\n",
      "2017-09-17 22:28:27,017 Epoch[4] Train-accuracy=0.913225\n",
      "2017-09-17 22:28:27,020 Epoch[4] Time cost=28.072\n",
      "2017-09-17 22:28:32,380 Epoch[4] Validation-accuracy=0.909180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('accuracy', 0.9086174242424242)]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2 # This is binary classification\n",
    "batch_per_gpu = 128\n",
    "num_gpus = 1\n",
    "epoch = 5\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train, val) = get_iterators(batch_size)\n",
    "mod = fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus, epoch)\n",
    "metric = mx.metric.Accuracy()\n",
    "mod_score = mod.score(val, metric)\n",
    "print mod_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prefix = 'caffenet-mxnet-jump-start-128-bootstrap'\n",
    "# mc = mod.save_checkpoint(prefix, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
